import numpy as np
import pandas as pd
import random

VECTOR_LENGTH = 300

# function definitions

def gen_ids(num_ids:int):
    '''Generates a list of "post id" strings that are meant to stand-in for post titles

    Args:
        num_ids: the number of ids to generate

    Returns:
        A list of strings
    '''
    ids = list()
    for i in range(num_ids):
        ids.append(f'post_{i}')
    return(ids)

def gen_posts(num_posts:int, num_groups:int):
    '''Generates a dataframe representing a set of posts and each post's affinity to each group

    Args:
        num_posts: the number of posts to generate
        num_groups: the number of groups users may be a part of

    Returns:
        A pandas.Dataframe indexed by strings representing post
        titles, with columns for each group, with each group 
        column containing float64 data.
    '''
    data = dict()
    
    ids = gen_ids(num_posts)
    data['SUBMISSION_ID'] = ids
    for i in range(num_groups):
        data[f'GROUP_{i}'] = pd.Series(np.random.random(num_posts))
    df = pd.DataFrame(data=data) 
    df.set_index('SUBMISSION_ID',inplace=True)
    return( df )

def gen_users(groups:list):
    '''Generate a dataframe representing users who are members of certain groups

    Args:
        groups: A list of integers. The value at each index 
        specifies the number of users who are members of the
        corresponding group

    Returns:
        A pandas.Dataframe indexed by strings representing
        user names, and a column representing the group
        the user is a part of
    '''
    data=dict()
    usernames = list()
    groupnames = list()

    usr_counter = 0
    for grp_id in range(len(groups)):
        grp_size = groups[grp_id]
        for usr in range(grp_size):
            usernames.append(f'usr_{usr_counter}')
            usr_counter += 1
            groupnames.append(f'GROUP_{grp_id}')
    data['USERNAME'] = usernames
    data['GROUP'] = groupnames
    df = pd.DataFrame(data=data)
    df.set_index('USERNAME',inplace=True)
    return( df )

def gen_votes(users, posts, avg_votes, std_votes, min_votes=1, max_votes=np.nan):
    '''Generate a dataframe reprsenting the votes a set of users may make on a set of posts

    Args:
        users: A Dataframe of users (as generated by gen_users)
        posts: A Dataframe of posts (as generated by gen_posts)
        avg_votes: The average number of votes expected from 
                   each user (not accounting for the floor)
        std_votes: The standard deviation of votes expected from 
                   each user (not accounting for the floor)
        min_votes: The minimum number of votes each user must
                   make.
        max_votes:  The maximum number of votes each user must
                   make (no maximum if np.nan)

    Returns:
        A pandas.Dataframe containing columns POST_ID, USERNAME, 
        and VOTE. POST_ID is a string representing a unique post
        title, USERNAME is a string representing a unique user, 
        and VOTE is either the strings 'upvote' or 'downvote'
        representing the vote the user made on the post
    '''
    votes = list()
    post_ids = list()
    usernames = list()
    data = dict()
    
    for usr_name,usr_group in users.itertuples():
        num_votes = int(np.random.normal(loc=avg_votes, scale=std_votes, size=1)[0])
        num_votes = np.nanmin([num_votes,max_votes])
        num_votes = np.nanmax([num_votes,min_votes])
        num_votes = int(np.round(num_votes))
        posts_sample = posts.sample(num_votes)
        for post_tuple in posts_sample.itertuples():
            post_id = post_tuple.Index
            prob = getattr(post_tuple,usr_group)
            
            post_ids.append(post_id)
            usernames.append(usr_name)
            
            if random.random() <= prob:
                votes.append('upvote')
            else:
                votes.append('downvote')
    data['SUBMISSION_ID'] = post_ids
    data['USERNAME'] = usernames
    data['VOTE'] = votes

    df = pd.DataFrame(data=data)
    return( df )    

def reset_users(users_df):
    '''Reset or initialize a users dataframe (as generated by gen_users) in preparation for training

    Args:
        users_df: a pandas.Dataframe object (as generated by gen_users)

    Notes:
        Does not have a return, modifies the users_df dataframe in-place
    '''
    vectors = [ np.random.choice([1,-1],VECTOR_LENGTH) for _ in range(len(users_df)) ]
    intermediary_vectors = [ np.zeros(VECTOR_LENGTH) for _ in range(len(users_df)) ]
    users_df['VECTOR'] = vectors
    users_df['INTERMEDIARY'] = intermediary_vectors
    users_df['INTERMEDIARY'] = users_df['INTERMEDIARY'].apply(lambda cell:np.zeros(VECTOR_LENGTH)) ## ?

def iterate_graph(votes_df, users_df):
    '''This is the first stage of the algorithm.
       Iterate the graph formed by users and their interactions with each-other through posts.
       Update (in-place) the *intermediary* vectors that represent user interests/viewpoints.
       This can be run several times in a row to iterate over different graphs or piecemeal
       iterate over different parts of a graph. Once intended all data has been consumed,
       run resolve_graph to produce mature vectores to represent uer interests/viewpoints.

    Args:
        votes_df: a pandas.Dataframe object (as generated by gen_votes)
        users_df: a pandas.Dataframe object (as generated by gen_users)

    Notes:
        Does not have a return, modifies the users_df dataframe in-place.
    '''
    count = 0
    len_groupby = len(votes_df.groupby('SUBMISSION_ID'))
    grp_vector = np.zeros(VECTOR_LENGTH)
    for grp in votes_df.groupby('SUBMISSION_ID'):
        count += 1
        if (count %100 ==0):
            print(f'          {count} / {len_groupby}         ', end='\r')
    
        grp_vector[::] = 0
        grp_id = grp[0]
        grp_votes = grp[1]

        if len(grp_votes) == 1:
            continue
        
        for vote in grp_votes.itertuples():
            try:
                if vote.VOTE == 'upvote':
                    grp_vector += users_df.loc[vote.USERNAME]['VECTOR']
                elif vote.VOTE == 'downvote':
                    grp_vector -= users_df.loc[vote.USERNAME]['VECTOR']
            except:
                print(users_df.loc[vote.USERNAME]['VECTOR']) 
        #########grp_vector /= len(grp_votes)
        for vote in grp_votes.itertuples():
            if vote.VOTE == 'upvote':
                if (len(grp_votes)-1) > 0:
                    users_df.at[vote.USERNAME,'INTERMEDIARY'] += (grp_vector-users_df.loc[vote.USERNAME]['VECTOR'])/(len(grp_votes)-1)
            elif vote.VOTE == 'downvote':
                if (len(grp_votes)-1) > 0:
                    users_df.at[vote.USERNAME,'INTERMEDIARY'] -= (grp_vector+users_df.loc[vote.USERNAME]['VECTOR'])/(len(grp_votes)-1)

def resolve_graph(users_df):
    '''Apply a normalization to the vectors generated by iterate_graph to 
       produce mature vectors that represent user interests/viewpoints.

    Args:
        users_df: a pandas.Dataframe object (as generated by gen_users)    

    Notes:
        Does not have a return, modifies the users_df dataframe in-place.
    '''
    users_df['INTERMEDIARY'] = users_df['INTERMEDIARY'].apply(lambda cell:cell/np.mean(np.abs(cell)))
    avg_vector = np.mean(users_df['INTERMEDIARY']) #
    users_df['INTERMEDIARY'] = users_df['INTERMEDIARY'].apply(lambda cell:cell-avg_vector) #
    users_df['INTERMEDIARY'] = users_df['INTERMEDIARY'].apply(lambda cell:cell/np.mean(np.abs(cell)))
    users_df['VECTOR'] = users_df['INTERMEDIARY'].apply(lambda cell:cell.copy())

def reset_post_stats(posts_df):
    posts_df['SIMPLE_SCORE'] = 0.0
    posts_df['DIVERSITY_SCORE'] = 0.0
    #posts_df['SIMPLE_RANK'] = -1.0
    #posts_df['NEEKA_RANK'] = -1.0
    posts_df['DISLIKE_DIVERSITY'] = 0.0
    posts_df['LIKE_CENTRICITY'] = 0.0
    posts_df['DISLIKE_CENTRICITY'] = 0.0
    posts_df['UPVOTES'] = 0
    posts_df['DOWNVOTES'] = 0
    posts_df['SIMPLE_SCORE'] = 0.0
    posts_df['DIFFERENCE_RANK'] = 0.0
    posts_df['GROUP_DISTANCE'] = 0.0
    posts_df['GROUP0_X'] = 0.0
    posts_df['GROUP1_X'] = 0.0

def calculate_post_stats(users_df, votes_df, posts_df):
    '''Produce statistics for each post that are used in calculation of Neeka score and other analyses

    Args:
        users_df: a pandas.Dataframe object, containing mature vectors
                  (as generated by gen_users and prepared with 
                  iterate_graph and resolve_graph)
        votes_df: a pandas.Dataframe object (as generated by gen_votes)
        posts_df: A Dataframe of posts (as generated by gen_posts)

    Notes:
        Has no return; modifies posts_df in-place
    '''
    avg_vector = np.mean(users_df['VECTOR'])
    
    for grp in votes_df.groupby('SUBMISSION_ID'):
        grp_id = grp[0]
        grp_votes = grp[1]
        posts_df.at[grp_id,'VOTES'] = len(grp_votes)
        upvotes = 0
        upvote_vector_sum = np.zeros(VECTOR_LENGTH)
        downvotes = 0
        downvote_vector_sum = np.zeros(VECTOR_LENGTH)

        group0_upvotes = 0
        group1_upvotes = 0
        group0_downvotes = 0
        group1_downvotes = 0
        
        all_vector_sum = 0
        for vote in grp_votes.itertuples():
            uservec =  users_df.loc[vote.USERNAME]['VECTOR']
            
            if vote.VOTE == 'upvote':
                upvote_vector_sum += uservec
                upvotes += 1
                if 'GROUP' in users_df.columns:
                    usergroup =  users_df.loc[vote.USERNAME]['GROUP']
                    if usergroup == 'GROUP_0':
                        group0_upvotes += 1
                    elif usergroup == 'GROUP_1':
                        group1_upvotes += 1
                    elif usergroup == "NO_GROUP":
                        pass
                    else:
                        raise Exception(f"unknown group: '{usergroup}'")
            elif vote.VOTE == 'downvote':
                downvote_vector_sum += uservec
                downvotes += 1
                if 'GROUP' in users_df.columns:
                    usergroup =  users_df.loc[vote.USERNAME]['GROUP']
                    if usergroup == 'GROUP_0':
                        group0_downvotes += 1
                    elif usergroup == 'GROUP_1':
                        group1_downvotes += 1
                    elif usergroup == "NO_GROUP":
                        pass
                    else:
                        raise Exception(f"unknown group: '{usergroup}'")
    
        upvote_vector_avg = np.zeros(VECTOR_LENGTH)
        downvote_vector_avg = np.zeros(VECTOR_LENGTH)
        
        up_dist_from_center_avg = np.nan
        down_dist_from_center_avg = np.nan
        if upvotes > 0:
            upvote_vector_avg = upvote_vector_sum/upvotes
            up_dist_from_center_avg = np.sum(np.abs(upvote_vector_avg - avg_vector))
    
        if downvotes > 0:
            downvote_vector_avg = downvote_vector_sum/downvotes
            down_dist_from_center_avg = np.sum(np.abs(downvote_vector_avg - avg_vector))
    
        upvote_vector_dist_sum = 0
        downvote_vector_dist_sum = 0
        
        for vote in grp_votes.itertuples():
            if vote.VOTE == 'upvote':
                upvote_vector_dist_sum += np.sum(np.abs(upvote_vector_avg - users_df.loc[vote.USERNAME]['VECTOR']))
            elif vote.VOTE == 'downvote':
                downvote_vector_dist_sum += np.sum(np.abs(downvote_vector_avg - users_df.loc[vote.USERNAME]['VECTOR']))
    
        all_vector_dist_avg = 0
        upvote_vector_dist_avg = 0
        downvote_vector_dist_avg = 0
    
        if upvotes > 0:
            upvote_vector_dist_avg = upvote_vector_dist_sum/upvotes 
        if downvotes > 0:
            downvote_vector_dist_avg = downvote_vector_dist_sum/downvotes

        # percentage 
        group0_x = np.nan
        if 'GROUP_0' in posts_df.columns:
            group0_x = posts_df.at[grp_id,'GROUP_0']
        if group0_upvotes+group0_downvotes > 0:
            group0_x = group0_upvotes/(group0_upvotes+group0_downvotes)
        posts_df.at[grp_id,'GROUP0_X'] = group0_x

        # percentage
        group1_x = np.nan
        if 'GROUP_1' in posts_df.columns:
            group1_x = posts_df.at[grp_id,'GROUP_1']
        if group1_upvotes+group1_downvotes > 0:
            group1_x = group1_upvotes/(group1_upvotes+group1_downvotes)
        posts_df.at[grp_id,'GROUP1_X'] = group1_x

        POLARITY = np.sum(np.abs(upvote_vector_avg-downvote_vector_avg))
        
        posts_df.at[grp_id,'POLARITY']    = np.float64(POLARITY)
        posts_df.at[grp_id,'LIKE_DIVERSITY']    = np.float64(upvote_vector_dist_avg)
        posts_df.at[grp_id,'LIKE_CENTRICITY']    = np.float64(up_dist_from_center_avg)
        posts_df.at[grp_id,'DISLIKE_CENTRICITY'] = np.float64(down_dist_from_center_avg)
        posts_df.at[grp_id,'DISLIKE_DIVERSITY'] = np.float64(downvote_vector_dist_avg)
        posts_df.at[grp_id,'UPVOTES'] = np.int64(upvotes)
        posts_df.at[grp_id,'DOWNVOTES'] = np.int64(downvotes)
        posts_df.at[grp_id,'SIMPLE_SCORE'] = np.float64(upvotes-downvotes)
        posts_df.at[grp_id,'GROUP_DISTANCE'] = np.float64(np.sum(np.abs(upvote_vector_avg-downvote_vector_avg)))
        posts_df.at[grp_id,'GROUP0_UPVOTES'] = group0_upvotes
        posts_df.at[grp_id,'GROUP1_UPVOTES'] = group1_upvotes
        posts_df.at[grp_id,'GROUP0_DOWNVOTES'] = group0_downvotes
        posts_df.at[grp_id,'GROUP1_DOWNVOTES'] = group1_downvotes


def calculate_percentile_rank(posts_df):
    '''Calculate percentile rank of posts for the simple score, the Neeka score, and the difference between each

    Args:
        posts_df: A Dataframe of posts (as generated by gen_posts 
                  and enriched and neeka_score_calculation)

    Notes:
        Has no return; modifies posts_df in-place
        ONLY USED inside neeka_score_calculation
    '''
    # TODO: why isn't this just part of neeka_score_calculation??
    posts_df['SIMPLE_PERCENTILE'] = posts_df['SIMPLE_SCORE'].rank(pct = True, ascending = True).array
    posts_df['NEEKA_PERCENTILE'] = posts_df['NEEKA_SCORE'].rank(pct = True, ascending = True).array
    posts_df['DIFFERENCE_RANK'] = posts_df.apply(lambda row:row['NEEKA_PERCENTILE']-row['SIMPLE_PERCENTILE'], axis=1)

def neeka_score_calculation(posts_df):
    '''Calculate the Neeka score for each post

    Args:
        posts_df: A Dataframe of posts (as generated by gen_posts)

    Notes:
        Has no return; modifies posts_df in-place
    '''
    AVG_LIKE_CENTRICITY = np.mean(posts_df['LIKE_CENTRICITY'])
    AVG_DISLIKE_CENTRICITY = np.mean(posts_df['DISLIKE_CENTRICITY'])
    AVG_CENTRICITY = (AVG_LIKE_CENTRICITY+AVG_DISLIKE_CENTRICITY)/2
    for post_row in posts_df.iterrows():
        post_id = post_row[0]
        post = post_row[1]
        LIKE_DIVERSITY = post['LIKE_DIVERSITY']
        LIKE_CENTRICITY = post['LIKE_CENTRICITY']
        DISLIKE_CENTRICITY = post['DISLIKE_CENTRICITY']
        DISLIKE_DIVERSITY = post['DISLIKE_DIVERSITY']
        SIMPLE_SCORE = post['SIMPLE_SCORE']
        UPVOTES = post['UPVOTES']
        DOWNVOTES = post['DOWNVOTES']
        GROUP_DISTANCE = post['GROUP_DISTANCE']
        POLARITY = post['POLARITY']
        
        if UPVOTES > 0:
            up_score = np.float64(LIKE_DIVERSITY + AVG_CENTRICITY - POLARITY/2)*UPVOTES
        else:
            up_score = 0

        if DOWNVOTES > 0:
            down_score = np.float64(DISLIKE_DIVERSITY + AVG_CENTRICITY + POLARITY/2)*DOWNVOTES
        else:
            down_score = 0
        posts_df.at[post_id,'NEEKA_SCORE'] = ( up_score - down_score )
    calculate_percentile_rank(posts_df)

def calculate_test_results(posts_df):
    
    # optimize for posts that are liked by both groups
    metric = posts_df['GROUP0_X']*posts_df['GROUP1_X']
    optimal = (metric).rank(pct = True, ascending = True)
    suboptimal =  (metric).rank(pct = True, ascending = False)
    simple_agreement = 1-np.mean(np.abs(optimal-posts_df['SIMPLE_PERCENTILE']))*2
    neeka_agreement = 1-np.mean(np.abs(optimal-posts_df['NEEKA_PERCENTILE']))*2

    average_change = np.mean(np.abs(posts_df['SIMPLE_PERCENTILE']-posts_df['NEEKA_PERCENTILE']))

    # optimize for posts that are not favored by one group, but not the other
    apolar_metric = 1-np.abs(posts_df['GROUP0_X']-posts_df['GROUP1_X'])
    apolar_optimal = (apolar_metric).rank(pct = True, ascending = True)
    apolar_suboptimal = (apolar_metric).rank(pct = True, ascending = False)
    simple_apolar = 1-np.mean(np.abs(apolar_optimal-posts_df['SIMPLE_PERCENTILE']))*2
    neeka_apolar = 1-np.mean(np.abs(apolar_optimal-posts_df['NEEKA_PERCENTILE']))*2

    # How much does the ranking favor GROUP0
    group0_bias_metric = posts_df['GROUP0_X']
    group0_bias_optimal = (group0_bias_metric).rank(pct = True, ascending = True)
    group0_bias_suboptimal =  (group0_bias_metric).rank(pct = True, ascending = False)
    simple_group0_bias = 1-np.mean(np.abs(group0_bias_optimal-posts_df['SIMPLE_PERCENTILE']))*2
    neeka_group0_bias = 1-np.mean(np.abs(group0_bias_optimal-posts_df['NEEKA_PERCENTILE']))*2

    # How much does the ranking favor GROUP1
    group1_bias_metric = posts_df['GROUP1_X']
    group1_bias_optimal = (group1_bias_metric).rank(pct = True, ascending = True)
    group1_bias_suboptimal =  (group1_bias_metric).rank(pct = True, ascending = False)
    simple_group1_bias = 1-np.mean(np.abs(group1_bias_optimal-posts_df['SIMPLE_PERCENTILE']))*2
    neeka_group1_bias = 1-np.mean(np.abs(group1_bias_optimal-posts_df['NEEKA_PERCENTILE']))*2

    # How much does the ranking favor neither group
    simple_neutrality = 1-np.abs(simple_group0_bias-simple_group1_bias)
    neeka_neutrality = 1-np.abs(neeka_group0_bias-neeka_group1_bias)

    # Combine the result statistics
    simple_quality = np.mean([simple_agreement,simple_apolar,simple_neutrality])
    neeka_quality = np.mean([neeka_agreement,neeka_apolar,neeka_neutrality])    

    results = {'simple_agreement':[simple_agreement], 'neeka_agreement':[neeka_agreement], 
              'simple_apolar':[simple_apolar], 'neeka_apolar':[neeka_apolar], 
              'simple_neutrality':[simple_neutrality], 'neeka_neutrality':[neeka_neutrality], 
              'simple_quality':[simple_quality], 'neeka_quality':[neeka_quality], 
              'simple_group0_bias':[simple_group0_bias], 'simple_group1_bias':[simple_group1_bias], 
              'neeka_group0_bias':[neeka_group0_bias], 'neeka_group1_bias':[neeka_group1_bias]}

    results = pd.DataFrame.from_dict(results)
    return results

def print_test_results(results):
    simple_agreement   = results['simple_agreement'][0]
    simple_apolar      = results['simple_apolar'][0]
    simple_neutrality  = results['simple_neutrality'][0]
    simple_quality     = results['simple_quality'][0]
    simple_group0_bias = results['simple_group0_bias'][0]
    simple_group1_bias = results['simple_group1_bias'][0]
    neeka_agreement    = results['neeka_agreement'][0]
    neeka_apolar       = results['neeka_apolar'][0]
    neeka_neutrality   = results['neeka_neutrality'][0]
    neeka_quality      = results['neeka_quality'][0]
    neeka_group0_bias  = results['neeka_group0_bias'][0]
    neeka_group1_bias  = results['neeka_group1_bias'][0]
    
    s = f'''
    simple_agreement: {np.round( simple_agreement*100 , 2)} %
    neeka_agreement: {np.round( neeka_agreement*100 , 2)} %
    agreement_change: {np.round( (neeka_agreement-simple_agreement)*100 , 2)} %

    simple_apolar: {np.round( simple_apolar*100 , 2)} %
    neeka_apolar: {np.round( neeka_apolar*100 , 2)} %
    apolar_change: {np.round( (neeka_apolar-simple_apolar)*100 , 2)} %

    simple_neutrality: {np.round( simple_neutrality*100 , 2)} %
    neeka_neutrality: {np.round( neeka_neutrality*100 , 2)} %
    neutrality_change: {np.round( (neeka_neutrality-simple_neutrality)*100 , 2)} %

    Overall:
    simple_quality: {np.round( simple_quality*100 , 2)} %
    neeka_quality: {np.round( neeka_quality*100 , 2)} %
    quality_change: {np.round( (neeka_quality-simple_quality)*100 , 2)} %

    #######################################

    simple_group0_bias: {np.round( simple_group0_bias*100 , 2)} %
    simple_group1_bias: {np.round( simple_group1_bias*100 , 2)} %
    
    neeka_group0_bias: {np.round( neeka_group0_bias*100 , 2)} %
    neeka_group1_bias: {np.round( neeka_group1_bias*100 , 2)} %
    '''
    print(s)
    